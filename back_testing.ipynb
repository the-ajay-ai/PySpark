{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OaRdOWZiTVpr"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PlBcw5zFYOgj"
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Back-testing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "koPMaRhJYmje"
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('./Data/glass.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HBzlpzmYtF8",
    "outputId": "bc91ba06-0b55-437f-e86f-0d00af4b0746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+----+----+-----+----+----+---+----+----+\n",
      "|Index|     ri|   na|  mg|  al|   si|   k|  ca| ba|  fe|type|\n",
      "+-----+-------+-----+----+----+-----+----+----+---+----+----+\n",
      "|    1|1.52101|13.64|4.49| 1.1|71.78|0.06|8.75|0.0| 0.0|   1|\n",
      "|    2|1.51761|13.89| 3.6|1.36|72.73|0.48|7.83|0.0| 0.0|   1|\n",
      "|    3|1.51618|13.53|3.55|1.54|72.99|0.39|7.78|0.0| 0.0|   1|\n",
      "|    4|1.51766|13.21|3.69|1.29|72.61|0.57|8.22|0.0| 0.0|   1|\n",
      "|    5|1.51742|13.27|3.62|1.24|73.08|0.55|8.07|0.0| 0.0|   1|\n",
      "|    6|1.51596|12.79|3.61|1.62|72.97|0.64|8.07|0.0|0.26|   1|\n",
      "|    7|1.51743| 13.3| 3.6|1.14|73.09|0.58|8.17|0.0| 0.0|   1|\n",
      "|    8|1.51756|13.15|3.61|1.05|73.24|0.57|8.24|0.0| 0.0|   1|\n",
      "|    9|1.51918|14.04|3.58|1.37|72.08|0.56| 8.3|0.0| 0.0|   1|\n",
      "|   10|1.51755| 13.0| 3.6|1.36|72.99|0.57| 8.4|0.0|0.11|   1|\n",
      "|   11|1.51571|12.72|3.46|1.56| 73.2|0.67|8.09|0.0|0.24|   1|\n",
      "|   12|1.51763| 12.8|3.66|1.27|73.01| 0.6|8.56|0.0| 0.0|   1|\n",
      "|   13|1.51589|12.88|3.43| 1.4|73.28|0.69|8.05|0.0|0.24|   1|\n",
      "|   14|1.51748|12.86|3.56|1.27|73.21|0.54|8.38|0.0|0.17|   1|\n",
      "|   15|1.51763|12.61|3.59|1.31|73.29|0.58| 8.5|0.0| 0.0|   1|\n",
      "|   16|1.51761|12.81|3.54|1.23|73.24|0.58|8.39|0.0| 0.0|   1|\n",
      "|   17|1.51784|12.68|3.67|1.16|73.11|0.61| 8.7|0.0| 0.0|   1|\n",
      "|   18|1.52196|14.36|3.85|0.89|71.36|0.15|9.15|0.0| 0.0|   1|\n",
      "|   19|1.51911| 13.9|3.73|1.18|72.12|0.06|8.89|0.0| 0.0|   1|\n",
      "|   20|1.51735|13.02|3.54|1.69|72.73|0.54|8.44|0.0|0.07|   1|\n",
      "+-----+-------+-----+----+----+-----+----+----+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FW2q0ygZ-bY",
    "outputId": "6379f370-4100-4022-f4f4-36d8ca565477"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Index', 'ri', 'na', 'mg', 'al', 'si', 'k', 'ca', 'ba', 'fe', 'type']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9aaty9VKesq-"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pysparkling.ml import H2ODRF, H2OGLM, H2OXGBoost, H2ODeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GEO5A14RZHhk"
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['ri', 'na', 'mg', 'al', 'si', 'k', 'ca', 'ba', 'fe'], outputCol='features')\n",
    "df2 = assembler.transform(df)\n",
    "final_data = df2.select('features', \"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "k4bIrs1caGje"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(featuresCol='features', labelCol=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JResLcdEaYf8"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "D5xGae8ual6C"
   },
   "outputs": [],
   "source": [
    "model = model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cI6_hGuHaphv"
   },
   "outputs": [],
   "source": [
    "predict = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LPWIVaNka0Uf",
    "outputId": "791f50be-b3f1-4672-8600-6adff32eb627"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+--------------------+----------+\n",
      "|            features|type|       rawPrediction|         probability|prediction|\n",
      "+--------------------+----+--------------------+--------------------+----------+\n",
      "|[1.51571,12.72,3....|   1|[1.36533224363129...|[0.79662496039350...|       0.0|\n",
      "|[1.51574,14.86,3....|   0|[2.15969526345010...|[0.89657129336781...|       0.0|\n",
      "|[1.51589,12.88,3....|   1|[0.72398013404823...|[0.67348286685616...|       0.0|\n",
      "|[1.5159,12.82,3.5...|   0|[2.09450057207828...|[0.89036751333745...|       0.0|\n",
      "|[1.5159,13.24,3.3...|   0|[0.41924282696132...|[0.60330205081767...|       0.0|\n",
      "|[1.51593,13.09,3....|   0|[0.31484918918539...|[0.57806844975788...|       0.0|\n",
      "|[1.51645,13.4,3.4...|   0|[1.02896917071868...|[0.73671599927488...|       0.0|\n",
      "|[1.51646,13.41,3....|   0|[-0.5721530761172...|[0.36074016235209...|       1.0|\n",
      "|[1.51652,13.56,3....|   0|[0.52401257713743...|[0.62808556133854...|       0.0|\n",
      "|[1.5166,12.99,3.1...|   0|[0.51072831007962...|[0.62497719182733...|       0.0|\n",
      "|[1.51673,13.3,3.6...|   0|[1.54512764190998...|[0.82420889753286...|       0.0|\n",
      "|[1.51687,13.23,3....|   0|[0.36877823151389...|[0.59116372313716...|       0.0|\n",
      "|[1.51707,13.48,3....|   0|[1.59638355940241...|[0.83151233060203...|       0.0|\n",
      "|[1.51711,12.89,3....|   0|[0.55881920887221...|[0.63617928400301...|       0.0|\n",
      "|[1.51721,12.87,3....|   1|[-0.2821954186318...|[0.42991562231730...|       1.0|\n",
      "|[1.51743,13.3,3.6...|   1|[-1.2479012659182...|[0.22306365116448...|       1.0|\n",
      "|[1.51747,12.84,3....|   1|[-1.2360350149562...|[0.22512690276289...|       1.0|\n",
      "|[1.51748,12.86,3....|   1|[-0.1980128468593...|[0.45065790457244...|       1.0|\n",
      "|[1.51751,12.81,3....|   1|[-0.3542414526280...|[0.41235425914125...|       1.0|\n",
      "|[1.51754,13.48,3....|   1|[-1.2762520635254...|[0.21818888062063...|       1.0|\n",
      "+--------------------+----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BNQxjPy6bBc_"
   },
   "outputs": [],
   "source": [
    "def generateScore(prob):\n",
    "    pdo = 20\n",
    "    odds = None\n",
    "    # if 1 not in prob:\n",
    "    odds = prob/(1-prob)\n",
    "    factor = pdo/np.log(2)\n",
    "    offset = 500 - factor*np.log(pdo)\n",
    "\n",
    "    score = offset + factor*np.log(odds)\n",
    "    return score\n",
    "\n",
    "def rank_order_df(developmentProb, monitoringProb, development_y, monitoring_y):\n",
    "    developmentScore = generateScore(developmentProb)\n",
    "    monitoringScore = generateScore(monitoringProb)\n",
    "    temp1 = {'score': developmentScore.reshape(-1), 'y': development_y.reshape(-1)}\n",
    "    development = pd.DataFrame(temp1)\n",
    "    temp2 = {'score': monitoringScore.reshape(-1), 'y': monitoring_y.reshape(-1)}\n",
    "    monitoring = pd.DataFrame(temp2)\n",
    "    \n",
    "    size = 11\n",
    "    mini = np.min(developmentScore)\n",
    "    maxi = np.max(monitoringScore)\n",
    "    add = (maxi-mini)/size\n",
    "    interval = [mini if (i == 0) else (mini := mini + add) for i in range(size)]    \n",
    "    development_dr=[]\n",
    "    rank_order_interval=[]\n",
    "    rank_order_devlopment_dr=[]\n",
    "    rank_order_monitoring_dr=[]\n",
    "    for i in range(len(interval)-1):\n",
    "        x= \"[\"+str(round(interval[i]))+\"-\"+str(round(interval[i+1]))+\")\"\n",
    "        rank_order_interval.append(x)\n",
    "        # print(development[\"score\"]>=interval[i])\n",
    "        development_alert=development[(development[\"score\"]>=interval[i]) & (development[\"score\"]<interval[i+1])][\"y\"].values \n",
    "        if len(development_alert)==0:\n",
    "            rank_order_devlopment_dr.append(0)\n",
    "        else:\n",
    "            rank_order_devlopment_dr.append(sum(development_alert)/len(development_alert))\n",
    "        \n",
    "        monitoring_alert=monitoring[(monitoring[\"score\"]>=interval[i]) & (monitoring[\"score\"]<interval[i+1])][\"y\"].values\n",
    "        if len(monitoring_alert)==0:\n",
    "            rank_order_monitoring_dr.append(0)\n",
    "        else:\n",
    "            rank_order_monitoring_dr.append(sum(monitoring_alert)/len(monitoring_alert))\n",
    "    \n",
    "    \n",
    "    df=pd.DataFrame(list(zip(rank_order_interval,  rank_order_devlopment_dr, rank_order_monitoring_dr)),\n",
    "              columns=[\"Interval\",\"Development Default Rate\",\"Monitoring Default Rate\"])\n",
    "    df[\"Interval\"][0]=\"< \"+(df.Interval[0])\n",
    "    df[\"Interval\"][size-2]=\">=\"+df[\"Interval\"][size-2].split(\"-\")[0][1:]\n",
    "    df= df.round(2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def rank_order(development,monitoring,model,target):\n",
    "  prob = udf(lambda v: float(v[1]), FloatType())\n",
    "  monitoring_model = model.transform(monitoring)\n",
    "  monitoringProb = monitoring_model.select(prob('probability'))\n",
    "  development_model = model.transform(development)\n",
    "  developmentProb = development_model.select(prob('probability'))\n",
    "  development_y = np.array(development.select(target).collect())\n",
    "  monitoring_y = np.array(monitoring.select(target).collect())\n",
    "  df=rank_order_df(developmentProb.toPandas().values, monitoringProb.toPandas().values, development_y, monitoring_y)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "6m7II9bWcIET",
    "outputId": "e3fce20b-d9e6-4d01-9856-f5da72fc72f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-73a1051aaa39>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Interval\"][0]=\"< \"+(df.Interval[0])\n",
      "<ipython-input-13-73a1051aaa39>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Interval\"][size-2]=\">=\"+df[\"Interval\"][size-2].split(\"-\")[0][1:]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>Development Default Rate</th>\n",
       "      <th>Monitoring Default Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; [152-182)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[182-212)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[212-242)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[242-271)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[271-301)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[301-331)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[331-361)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[361-390)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[390-420)</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;=420</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Interval  Development Default Rate  Monitoring Default Rate\n",
       "0  < [152-182)                      0.00                     0.00\n",
       "1    [182-212)                      0.00                     0.00\n",
       "2    [212-242)                      0.00                     0.00\n",
       "3    [242-271)                      0.00                     0.00\n",
       "4    [271-301)                      0.00                     0.00\n",
       "5    [301-331)                      0.00                     0.00\n",
       "6    [331-361)                      0.00                     0.00\n",
       "7    [361-390)                      0.25                     0.10\n",
       "8    [390-420)                      0.52                     0.31\n",
       "9        >=420                      0.62                     0.70"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_order(train_data, test_data,model,\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-73a1051aaa39>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Interval\"][0]=\"< \"+(df.Interval[0])\n",
      "<ipython-input-13-73a1051aaa39>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Interval\"][size-2]=\">=\"+df[\"Interval\"][size-2].split(\"-\")[0][1:]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>Development Default Rate</th>\n",
       "      <th>Monitoring Default Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; [152-182)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[182-212)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[212-242)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[242-271)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[271-301)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[301-331)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[331-361)</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[361-390)</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[390-420)</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;=420</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Interval  Development Default Rate  Monitoring Default Rate\n",
       "0  < [152-182)                      0.00                     0.00\n",
       "1    [182-212)                      0.00                     0.00\n",
       "2    [212-242)                      0.00                     0.00\n",
       "3    [242-271)                      0.00                     0.00\n",
       "4    [271-301)                      0.00                     0.00\n",
       "5    [301-331)                      0.00                     0.00\n",
       "6    [331-361)                      0.00                     0.00\n",
       "7    [361-390)                      0.25                     0.10\n",
       "8    [390-420)                      0.52                     0.31\n",
       "9        >=420                      0.62                     0.70"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_order(train_data, test_data,model,\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(df, user):\n",
    "#     helper = Model_helper(username=user)\n",
    "#     colors = helper.preference_maker(2)\n",
    "    months =df['Interval']\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=months,\n",
    "        y=df[\"Development Default Rate\"],\n",
    "        name='development',\n",
    "        marker_color='rgba(0,0,0,255)'\n",
    "    ))\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=months,\n",
    "        y=df[\"Monitoring Default Rate\"],\n",
    "        name='monitoring',\n",
    "        marker_color='rgba(0,255,0,0)'\n",
    "    ))\n",
    "    fig.update_layout({'plot_bgcolor': 'rgba(0,0,0,0)', 'paper_bgcolor': 'rgba(0,0,0,0)'}, title={\n",
    "            'text': '<b>'+\"RANK-ORDER PLOT\"+'<b>',\n",
    "            'y':0.9,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'\n",
    "            }\n",
    "        )\n",
    "    fig.update_layout(\n",
    "      \n",
    "      )\n",
    "\n",
    "    fig.update_layout(yaxis_range=[0,1])\n",
    "    fig.update_layout(barmode='group', xaxis_tickangle=-45)\n",
    "    fig.update_xaxes(title_text='<b>' + 'Scores range' + '<b>',showline=True, linewidth=1, linecolor='black')\n",
    "    fig.update_yaxes(title_text='<b> Probabilities <b>',showline=True, linewidth=1, linecolor='black')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def rankorder(d_df,m_df,model,target,user):\n",
    "    prob = udf(lambda v: float(v[1]), FloatType())\n",
    "    monitoring_model = model.transform(m_df)\n",
    "    monitoringProb = monitoring_model.select(prob('probability'))\n",
    "    development_model = model.transform(d_df)\n",
    "    developmentProb = development_model.select(prob('probability'))\n",
    "    development_y = np.array(d_df.select(target).collect())\n",
    "    monitoring_y = np.array(m_df.select(target).collect())\n",
    "    df = rank_order_df(developmentProb.toPandas().values, monitoringProb.toPandas().values, development_y, monitoring_y)\n",
    "    fig=get_graph(df,user=user)\n",
    "    return df.round(3),fig,m_df,d_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-73a1051aaa39>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Interval\"][0]=\"< \"+(df.Interval[0])\n",
      "<ipython-input-13-73a1051aaa39>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Interval\"][size-2]=\">=\"+df[\"Interval\"][size-2].split(\"-\")[0][1:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      Interval  Development Default Rate  Monitoring Default Rate\n",
       " 0  < [152-182)                      0.00                     0.00\n",
       " 1    [182-212)                      0.00                     0.00\n",
       " 2    [212-242)                      0.00                     0.00\n",
       " 3    [242-271)                      0.00                     0.00\n",
       " 4    [271-301)                      0.00                     0.00\n",
       " 5    [301-331)                      0.00                     0.00\n",
       " 6    [331-361)                      0.00                     0.00\n",
       " 7    [361-390)                      0.25                     0.10\n",
       " 8    [390-420)                      0.52                     0.31\n",
       " 9        >=420                      0.62                     0.70,\n",
       " Figure({\n",
       "     'data': [{'marker': {'color': 'rgba(0,0,0,255)'},\n",
       "               'name': 'development',\n",
       "               'type': 'bar',\n",
       "               'x': array(['< [152-182)', '[182-212)', '[212-242)', '[242-271)', '[271-301)',\n",
       "                           '[301-331)', '[331-361)', '[361-390)', '[390-420)', '>=420'],\n",
       "                          dtype=object),\n",
       "               'y': array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.52, 0.62])},\n",
       "              {'marker': {'color': 'rgba(0,255,0,0)'},\n",
       "               'name': 'monitoring',\n",
       "               'type': 'bar',\n",
       "               'x': array(['< [152-182)', '[182-212)', '[212-242)', '[242-271)', '[271-301)',\n",
       "                           '[301-331)', '[331-361)', '[361-390)', '[390-420)', '>=420'],\n",
       "                          dtype=object),\n",
       "               'y': array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.31, 0.7 ])}],\n",
       "     'layout': {'barmode': 'group',\n",
       "                'paper_bgcolor': 'rgba(0,0,0,0)',\n",
       "                'plot_bgcolor': 'rgba(0,0,0,0)',\n",
       "                'template': '...',\n",
       "                'title': {'text': '<b>RANK-ORDER PLOT<b>', 'x': 0.5, 'xanchor': 'center', 'y': 0.9, 'yanchor': 'top'},\n",
       "                'xaxis': {'linecolor': 'black',\n",
       "                          'linewidth': 1,\n",
       "                          'showline': True,\n",
       "                          'tickangle': -45,\n",
       "                          'title': {'text': '<b>Scores range<b>'}},\n",
       "                'yaxis': {'linecolor': 'black',\n",
       "                          'linewidth': 1,\n",
       "                          'range': [0, 1],\n",
       "                          'showline': True,\n",
       "                          'title': {'text': '<b> Probabilities <b>'}}}\n",
       " }),\n",
       " DataFrame[features: vector, type: int],\n",
       " DataFrame[features: vector, type: int])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankorder(train_data, test_data,model,\"type\",\"AJAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pysparkling.ml import H2ODRFClassifier, H2OGLMClassifier, H2OXGBoostClassifier, H2ODeepLearningClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurveMetrics(BinaryClassificationMetrics):\n",
    "    def __init__(self, *args):\n",
    "        super(CurveMetrics, self).__init__(*args)\n",
    "\n",
    "    def _to_list(self, rdd):\n",
    "        points = []\n",
    "        # Note this collect could be inefficient for large datasets\n",
    "        # considering there may be one probability per datapoint (at most)\n",
    "        # The Scala version takes a numBins parameter,\n",
    "        # but it doesn't seem possible to pass this from Python to Java\n",
    "        for row in rdd.collect():\n",
    "            # Results are returned as type scala.Tuple2,\n",
    "            # which doesn't appear to have a py4j mapping\n",
    "            points += [(float(row._1()), float(row._2()))]\n",
    "        return points\n",
    "\n",
    "    def get_curve(self, method):\n",
    "        rdd = getattr(self._java_model, method)().toJavaRDD()\n",
    "        return self._to_list(rdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "K0arE8bJefb9"
   },
   "outputs": [],
   "source": [
    "def get_model(train_data, model_key, n_fold):\n",
    "    model = None\n",
    "    grid = ParamGridBuilder().build()\n",
    "    evaluator = BinaryClassificationEvaluator()    \n",
    "    if model_key == 1:\n",
    "        model = RandomForestClassifier(labelCol='label', featuresCol=\"features\", numTrees=10)\n",
    "        crossval = CrossValidator(estimator=model, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2, numFolds=n_fold)\n",
    "        model = crossval.fit(train_data)\n",
    "    elif model_key == 2:\n",
    "        model = LogisticRegression(labelCol='label', featuresCol=\"features\", maxIter=100, regParam=0.001,elasticNetParam=1, standardization=True)\n",
    "        crossval = CrossValidator(estimator=model, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2, numFolds=n_fold)\n",
    "        model = crossval.fit(train_data)\n",
    "    elif model_key == 3:\n",
    "        model = LinearSVC(labelCol='label', featuresCol=\"features\", maxIter=1000, regParam=0.1)\n",
    "        crossval = CrossValidator(estimator=model, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2, numFolds=n_fold)\n",
    "        model = crossval.fit(train_data)\n",
    "    elif model_key == 4:\n",
    "        model = H2ODRFClassifier(labelCol='label', featuresCols=[\"features\"], nfolds=n_fold)\n",
    "        model = model.fit(train_data)\n",
    "    elif model_key == 5:\n",
    "        model = H2OGLMClassifier(labelCol='label', featuresCols=[\"features\"], nfolds=n_fold)\n",
    "        model = model.fit(train_data)\n",
    "    elif model_key == 6:\n",
    "        model = H2OXGBoostClassifier(labelCol='label', featuresCols=[\"features\"],nfolds=n_fold)\n",
    "        model = model.fit(train_data)\n",
    "    elif model_key == 7:\n",
    "        model = H2ODeepLearningClassifier(labelCol='label', featuresCols=[\"features\"], nfolds=n_fold)\n",
    "        model = model.fit(train_data)\n",
    "    return model\n",
    "\n",
    "\n",
    "def main_kfold(data, names, metrics, target, n_fold):\n",
    "    # helper = Model_helper(username=user)\n",
    "    # colors = helper.preference_maker(6)\n",
    "    data = data.withColumnRenamed(target, \"label\")\n",
    "    models = []\n",
    "    for i in names:\n",
    "        key = None\n",
    "        if i.lower() == 'RandomForestClassifier'.lower():\n",
    "            key = 1\n",
    "        elif i.lower() == 'LogisticRegression'.lower():\n",
    "            key = 2\n",
    "        elif i.lower() == 'LinearSVC'.lower():\n",
    "            key = 3\n",
    "        elif i.lower() == 'H2ODRFClassifier'.lower():\n",
    "            key = 4\n",
    "        elif i.lower() == 'H2OGLMClassifier'.lower():\n",
    "            key = 5\n",
    "        elif i.lower() == 'H2OXGBoostClassifier'.lower():\n",
    "            key = 6\n",
    "        elif i.lower() == 'H2ODeepLearningClassifier'.lower():\n",
    "            key = 7\n",
    "\n",
    "        t = get_model(data, key, n_fold)\n",
    "        models.append(t)\n",
    "\n",
    "\n",
    "    mean_acc = []\n",
    "    mean_f1 = []\n",
    "    mean_roc = []\n",
    "    mean_prec = []\n",
    "    mean_rec = []\n",
    "\n",
    "    figures = []\n",
    "    qw = 0\n",
    "#     col = colors\n",
    "#     col.append(['purple', 'violet', 'black', 'pink'])\n",
    "    for model in models:\n",
    "        m_name = names[qw]\n",
    "        model = model.transform(data)\n",
    "        if 'accuracy' in metrics:\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                          metricName=\"accuracy\")\n",
    "            accuracy = evaluator.evaluate(model)\n",
    "            mean_acc.append(round(accuracy, 2))\n",
    "        if 'f1' in metrics:\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "            f1 = evaluator.evaluate(model)\n",
    "            mean_f1.append(round(f1, 2))\n",
    "        if 'roc' in metrics:\n",
    "            evaluator = BinaryClassificationEvaluator(rawPredictionCol = \"prediction\")\n",
    "            roc = evaluator.evaluate(model)\n",
    "            mean_roc.append(round(roc, 2))\n",
    "        if 'precision' in metrics:\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"weightedPrecision\")\n",
    "            weightedPrecision = evaluator.evaluate(model)\n",
    "            mean_prec.append(round(weightedPrecision, 2))\n",
    "        if 'recall' in metrics:\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"weightedRecall\")\n",
    "            weightedRecall = evaluator.evaluate(model)\n",
    "            mean_rec.append(round(weightedRecall, 2))\n",
    "\n",
    "        # Compute ROC curve and area the curve\n",
    "        BCM = model.select(\"label\", 'probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['label'])))\n",
    "        curveMetrics = CurveMetrics(BCM)\n",
    "        roc_auc = curveMetrics.areaUnderROC\n",
    "        points = curveMetrics.get_curve('roc')\n",
    "        fpr = np.array([x[0] for x in points])\n",
    "        tpr = np.array([x[1] for x in points])\n",
    "        roc_auc = ' AUC Score= ' + str(round(roc_auc, 2))\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1],\n",
    "                                 mode='lines',\n",
    "                                 name='No Skill',\n",
    "                                 line=dict(color='black', width=0.5, dash='dash')))\n",
    "        fig.add_trace(go.Scatter(x=fpr, y=tpr,\n",
    "                                 mode='lines',\n",
    "                                 name=roc_auc,\n",
    "                                 line=dict(color=\"purple\", width=1)))\n",
    "        tit = 'ROC Curve for ' + m_name\n",
    "        # fig.update_layout(yaxis_title=\"<b> True Positive Rate </b>\", xaxis_title=\"<b> False Positive Rate </b>\")\n",
    "        fig.update_layout({'plot_bgcolor': 'rgba(0,0,0,0)', 'paper_bgcolor': 'rgba(0,0,0,0)'})\n",
    "        fig.update_xaxes(title_text='False Positive Rate', showline=True, linewidth=1, linecolor='black',\n",
    "                         rangemode='nonnegative')\n",
    "        fig.update_yaxes(title_text='True Positive Rate', showline=True, linewidth=1, linecolor='black',\n",
    "                         rangemode='nonnegative')\n",
    "        fig.update_layout(title={'text': tit,\n",
    "                                 'y': 0.9,\n",
    "                                 'x': 0.5,\n",
    "                                 'xanchor': 'center',\n",
    "                                 'yanchor': 'top'})\n",
    "    \n",
    "        figures.append(fig)\n",
    "        qw = qw + 1\n",
    "#     figure = tuple(figures)\n",
    "    \n",
    "    \n",
    "    table = pd.DataFrame()\n",
    "    table['Model Name'] = names\n",
    "    if 'accuracy' in metrics:\n",
    "        table['Mean Accuracy Score'] = mean_acc\n",
    "    if 'f1' in metrics:\n",
    "        table['Mean f1 Score'] = mean_f1\n",
    "    if 'roc' in metrics:\n",
    "        table['Mean AUCROC Score'] = mean_roc\n",
    "    if 'precision' in metrics:\n",
    "        table['Mean Precision Score'] = mean_prec\n",
    "    if 'recall' in metrics:\n",
    "        table['Mean Recall Score'] = mean_rec\n",
    "\n",
    "    return table, figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"accuracy\",'f1','roc','precision','recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|type|\n",
      "+--------------------+----+\n",
      "|[1.51215,12.99,3....|   1|\n",
      "|[1.51409,14.25,3....|   0|\n",
      "|[1.51574,14.86,3....|   0|\n",
      "|[1.51589,12.88,3....|   1|\n",
      "|[1.5159,12.82,3.5...|   0|\n",
      "|[1.5159,13.02,3.5...|   0|\n",
      "|[1.51592,12.86,3....|   0|\n",
      "|[1.51593,13.25,3....|   0|\n",
      "|[1.51596,12.79,3....|   1|\n",
      "|[1.51596,13.02,3....|   0|\n",
      "|[1.51605,12.9,3.4...|   0|\n",
      "|[1.51613,13.92,3....|   0|\n",
      "|[1.51618,13.53,3....|   1|\n",
      "|[1.51627,13.0,3.5...|   0|\n",
      "|[1.51631,13.34,3....|   0|\n",
      "|[1.51645,13.44,3....|   0|\n",
      "|[1.51646,13.41,3....|   0|\n",
      "|[1.51652,13.56,3....|   0|\n",
      "|[1.51655,12.75,2....|   0|\n",
      "|[1.5166,12.99,3.1...|   0|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o7683.fit.\n: java.lang.RuntimeException: H2OContext needs to be created in order to train the model. Please create one as H2OContext.getOrCreate().\n\tat ai.h2o.sparkling.H2OContext$.$anonfun$ensure$1(H2OContext.scala:416)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat ai.h2o.sparkling.H2OContext$.ensure(H2OContext.scala:416)\n\tat ai.h2o.sparkling.ml.algos.H2OAlgoCommonUtils.prepareDatasetForFitting(H2OAlgoCommonUtils.scala:82)\n\tat ai.h2o.sparkling.ml.algos.H2OAlgoCommonUtils.prepareDatasetForFitting$(H2OAlgoCommonUtils.scala:55)\n\tat ai.h2o.sparkling.ml.algos.classification.H2ODeepLearningClassifier.ai$h2o$sparkling$ml$algos$classification$H2OClassifier$$super$prepareDatasetForFitting(H2ODeepLearningClassifier.scala:24)\n\tat ai.h2o.sparkling.ml.algos.classification.H2OClassifier.prepareDatasetForFitting(H2OClassifier.scala:35)\n\tat ai.h2o.sparkling.ml.algos.classification.H2OClassifier.prepareDatasetForFitting$(H2OClassifier.scala:34)\n\tat ai.h2o.sparkling.ml.algos.classification.H2ODeepLearningClassifier.ai$h2o$sparkling$ml$algos$classification$DistributionForClassificationCheck$$super$prepareDatasetForFitting(H2ODeepLearningClassifier.scala:24)\n\tat ai.h2o.sparkling.ml.algos.classification.DistributionForClassificationCheck.prepareDatasetForFitting(DistributionForClassificationCheck.scala:33)\n\tat ai.h2o.sparkling.ml.algos.classification.DistributionForClassificationCheck.prepareDatasetForFitting$(DistributionForClassificationCheck.scala:27)\n\tat ai.h2o.sparkling.ml.algos.classification.H2ODeepLearningClassifier.prepareDatasetForFitting(H2ODeepLearningClassifier.scala:24)\n\tat ai.h2o.sparkling.ml.algos.H2OAlgorithm.fit(H2OAlgorithm.scala:53)\n\tat ai.h2o.sparkling.ml.algos.H2OSupervisedAlgorithm.fit(H2OSupervisedAlgorithm.scala:57)\n\tat ai.h2o.sparkling.ml.algos.H2ODeepLearning.fit(H2ODeepLearning.scala:35)\n\tat ai.h2o.sparkling.ml.algos.H2ODeepLearning.fit(H2ODeepLearning.scala:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-6176a50974a2>\u001b[0m in \u001b[0;36mmain_kfold\u001b[0;34m(data, names, metrics, target, n_fold)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-6176a50974a2>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(train_data, model_key, n_fold)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_key\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2ODeepLearningClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/master/lib/python3.9/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/master/lib/python3.9/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/master/lib/python3.9/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/master/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/master/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/master/lib/python3.9/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o7683.fit.\n: java.lang.RuntimeException: H2OContext needs to be created in order to train the model. Please create one as H2OContext.getOrCreate().\n\tat ai.h2o.sparkling.H2OContext$.$anonfun$ensure$1(H2OContext.scala:416)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat ai.h2o.sparkling.H2OContext$.ensure(H2OContext.scala:416)\n\tat ai.h2o.sparkling.ml.algos.H2OAlgoCommonUtils.prepareDatasetForFitting(H2OAlgoCommonUtils.scala:82)\n\tat ai.h2o.sparkling.ml.algos.H2OAlgoCommonUtils.prepareDatasetForFitting$(H2OAlgoCommonUtils.scala:55)\n\tat ai.h2o.sparkling.ml.algos.classification.H2ODeepLearningClassifier.ai$h2o$sparkling$ml$algos$classification$H2OClassifier$$super$prepareDatasetForFitting(H2ODeepLearningClassifier.scala:24)\n\tat ai.h2o.sparkling.ml.algos.classification.H2OClassifier.prepareDatasetForFitting(H2OClassifier.scala:35)\n\tat ai.h2o.sparkling.ml.algos.classification.H2OClassifier.prepareDatasetForFitting$(H2OClassifier.scala:34)\n\tat ai.h2o.sparkling.ml.algos.classification.H2ODeepLearningClassifier.ai$h2o$sparkling$ml$algos$classification$DistributionForClassificationCheck$$super$prepareDatasetForFitting(H2ODeepLearningClassifier.scala:24)\n\tat ai.h2o.sparkling.ml.algos.classification.DistributionForClassificationCheck.prepareDatasetForFitting(DistributionForClassificationCheck.scala:33)\n\tat ai.h2o.sparkling.ml.algos.classification.DistributionForClassificationCheck.prepareDatasetForFitting$(DistributionForClassificationCheck.scala:27)\n\tat ai.h2o.sparkling.ml.algos.classification.H2ODeepLearningClassifier.prepareDatasetForFitting(H2ODeepLearningClassifier.scala:24)\n\tat ai.h2o.sparkling.ml.algos.H2OAlgorithm.fit(H2OAlgorithm.scala:53)\n\tat ai.h2o.sparkling.ml.algos.H2OSupervisedAlgorithm.fit(H2OSupervisedAlgorithm.scala:57)\n\tat ai.h2o.sparkling.ml.algos.H2ODeepLearning.fit(H2ODeepLearning.scala:35)\n\tat ai.h2o.sparkling.ml.algos.H2ODeepLearning.fit(H2ODeepLearning.scala:27)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tab,fig  = main_kfold(train_data,[\"RandomForestClassifier\",\"LogisticRegression\"],metrics,\"type\")\n",
    "tab,fig = main_kfold(train_data,[\"H2ODeepLearningClassifier\"],metrics,\"type\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyo.plot(fig[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.tools as tls\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyo.plot(fig[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Accuracy Score</th>\n",
       "      <th>Mean f1 Score</th>\n",
       "      <th>Mean AUCROC Score</th>\n",
       "      <th>Mean Precision Score</th>\n",
       "      <th>Mean Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name  Mean Accuracy Score  Mean f1 Score  \\\n",
       "0  RandomForestClassifier                 0.97           0.97   \n",
       "1      LogisticRegression                 0.70           0.70   \n",
       "\n",
       "   Mean AUCROC Score  Mean Precision Score  Mean Recall Score  \n",
       "0               0.97                  0.97               0.97  \n",
       "1               0.70                  0.70               0.70  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "XR_kuxBeyh8_"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "lr = LogisticRegression()\n",
    "\n",
    "grid = ParamGridBuilder().build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator,parallelism=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rf3Y7L546ggH",
    "outputId": "945dde51-33d7-4f73-e1c9-45f35293bbe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1.52101,13.64,4....|    1|\n",
      "|[1.51761,13.89,3....|    1|\n",
      "|[1.51618,13.53,3....|    1|\n",
      "|[1.51766,13.21,3....|    1|\n",
      "|[1.51742,13.27,3....|    1|\n",
      "|[1.51596,12.79,3....|    1|\n",
      "|[1.51743,13.3,3.6...|    1|\n",
      "|[1.51756,13.15,3....|    1|\n",
      "|[1.51918,14.04,3....|    1|\n",
      "|[1.51755,13.0,3.6...|    1|\n",
      "|[1.51571,12.72,3....|    1|\n",
      "|[1.51763,12.8,3.6...|    1|\n",
      "|[1.51589,12.88,3....|    1|\n",
      "|[1.51748,12.86,3....|    1|\n",
      "|[1.51763,12.61,3....|    1|\n",
      "|[1.51761,12.81,3....|    1|\n",
      "|[1.51784,12.68,3....|    1|\n",
      "|[1.52196,14.36,3....|    1|\n",
      "|[1.51911,13.9,3.7...|    1|\n",
      "|[1.51735,13.02,3....|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = final_data.withColumnRenamed('type', 'label')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "kmF3MQDxyjr8"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "\n",
    "grid = ParamGridBuilder().build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "\n",
    "    parallelism=2, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "Q9q9C7T1ym1n"
   },
   "outputs": [],
   "source": [
    "model_demo = cv.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 FPR|                 TPR|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|                 0.0|\n",
      "|                 0.0|0.014285714285714285|\n",
      "|                 0.0| 0.04285714285714286|\n",
      "|                 0.0| 0.05714285714285714|\n",
      "|                 0.0| 0.07142857142857142|\n",
      "|                 0.0| 0.08571428571428572|\n",
      "|                 0.0|                 0.1|\n",
      "|                 0.0| 0.11428571428571428|\n",
      "|                 0.0| 0.12857142857142856|\n",
      "|                 0.0| 0.14285714285714285|\n",
      "|                 0.0| 0.15714285714285714|\n",
      "|                 0.0| 0.17142857142857143|\n",
      "|                 0.0| 0.18571428571428572|\n",
      "|                 0.0|                 0.2|\n",
      "|                 0.0| 0.21428571428571427|\n",
      "|0.013157894736842105| 0.21428571428571427|\n",
      "|0.013157894736842105| 0.22857142857142856|\n",
      "| 0.02631578947368421| 0.22857142857142856|\n",
      "| 0.02631578947368421| 0.24285714285714285|\n",
      "| 0.02631578947368421|  0.2571428571428571|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_demo.bestModel.summary.roc.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "nhjgdEMI6IDF"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(labelCol='label', featuresCol=\"features\", numTrees=10)\n",
    "grid = ParamGridBuilder().build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "cv = CrossValidator(estimator=rfc, estimatorParamMaps=grid, evaluator=evaluator,\n",
    "\n",
    "    parallelism=2, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "VZKX2WXRk5ve"
   },
   "outputs": [],
   "source": [
    "model_demo = cv.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CrossValidatorModel' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-1e9bb8416287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CrossValidatorModel' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model_demo.summary.roc.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_demo.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'round'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-1cea07f43058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m  \u001b[0;31m# P,R,F-1,TPR,FPR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevalute_mllib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_demo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-496ceb4f9b67>\u001b[0m in \u001b[0;36mevalute_mllib\u001b[0;34m(model, df)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mweightedRecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"f1-score\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mweightedPrecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mweightedRecall\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'round'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator  # P,R,F-1,TPR,FPR\n",
    "\n",
    "evalute_mllib(model_demo,final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dn3TSC67xLG",
    "outputId": "43154e1d-ce63-4aba-b8cb-f6f15b3bbf7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(model_demo.transform(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7g26Ocpg7V7b"
   },
   "outputs": [],
   "source": [
    "def evalute_mllib(model, df):\n",
    "    predictions = model.transform(df)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1 = evaluator.evaluate(predictions)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    weightedPrecision = evaluator.evaluate(predictions)\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    weightedRecall = evaluator.evaluate(predictions)\n",
    "    \n",
    "    return {\"accuracy\":accuracy.round(2),\"f1-score\":f1,\"precision\":weightedPrecision,\"recall\":weightedRecall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9726027397260274,\n",
       " 'f1-score': 0.9726027397260274,\n",
       " 'precision': 0.9736842105263158,\n",
       " 'recall': 0.9736842105263158}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalute_mllib(model_demo,final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankorder"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
